<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
		>
<channel>
	<title>Comments for enj</title>
	<atom:link href="http://enja.org/comments/feed/" rel="self" type="application/rss+xml" />
	<link>http://enja.org</link>
	<description>casin&#039; the joint since &#039;85</description>
	<lastBuildDate>Wed, 09 May 2012 06:22:44 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=3.3.2</generator>
	<item>
		<title>Comment on Floating down a Tributary by Krzysztof Kula</title>
		<link>http://enja.org/2012/05/07/floating-down-a-tributary/comment-page-1/#comment-1938</link>
		<dc:creator>Krzysztof Kula</dc:creator>
		<pubDate>Wed, 09 May 2012 06:22:44 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=767#comment-1938</guid>
		<description>Awesome! Thanks for this! :)</description>
		<content:encoded><![CDATA[<p>Awesome! Thanks for this! :)</p>
]]></content:encoded>
	</item>
	<item>
		<title>Comment on Floating down a Tributary by Rafael Ehlers</title>
		<link>http://enja.org/2012/05/07/floating-down-a-tributary/comment-page-1/#comment-1936</link>
		<dc:creator>Rafael Ehlers</dc:creator>
		<pubDate>Tue, 08 May 2012 23:45:08 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=767#comment-1936</guid>
		<description>Sorry but, everything it does (at the ui side) is showing a slider everytime you click on a integer in javascript. At least if it does a colorpick or something else. 

Seems to me that, all projects based on Bret Victor&#039;s talk only implement a few features, and that&#039;s not enough yet.

Anyway, congratulations on the effort.</description>
		<content:encoded><![CDATA[<p>Sorry but, everything it does (at the ui side) is showing a slider everytime you click on a integer in javascript. At least if it does a colorpick or something else. </p>
<p>Seems to me that, all projects based on Bret Victor&#8217;s talk only implement a few features, and that&#8217;s not enough yet.</p>
<p>Anyway, congratulations on the effort.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Comment on Floating down a Tributary by John Harrison</title>
		<link>http://enja.org/2012/05/07/floating-down-a-tributary/comment-page-1/#comment-1934</link>
		<dc:creator>John Harrison</dc:creator>
		<pubDate>Tue, 08 May 2012 21:53:30 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=767#comment-1934</guid>
		<description>soooo cool.  but the square circle illusion is going to make me vomit.  i can&#039;t handle it.</description>
		<content:encoded><![CDATA[<p>soooo cool.  but the square circle illusion is going to make me vomit.  i can&#8217;t handle it.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Comment on Adventures in PyOpenCL: Part 1 Getting Started with Python by Allan Douglas R. de Oliveira</title>
		<link>http://enja.org/2011/02/22/adventures-in-pyopencl-part-1-getting-started-with-python/comment-page-1/#comment-1932</link>
		<dc:creator>Allan Douglas R. de Oliveira</dc:creator>
		<pubDate>Tue, 08 May 2012 03:40:40 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=424#comment-1932</guid>
		<description>pm,

You need to run the test 1000 times. Like:
time1 = time()
for i in range(1000):
        c_result = (a + b) * (a + b) * (a / 2.0)
time2 = time()
print(&quot;Execution time with numpy: &quot;, time2 - time1, &quot;s&quot;)

You will see OpenCL performs better than NumPy (but NumPy is still pretty good, IMHO). On my machine:

(&#039;Execution time of test without OpenCL: &#039;, 9.549367904663086, &#039;s&#039;)
(&#039;Execution time with numpy: &#039;, 0.01725006103515625, &#039;s&#039;)
===============================================================
(&#039;Platform name:&#039;, &#039;Intel(R) OpenCL&#039;)
(&#039;Platform profile:&#039;, &#039;FULL_PROFILE&#039;)
(&#039;Platform vendor:&#039;, &#039;Intel(R) Corporation&#039;)
(&#039;Platform version:&#039;, &#039;OpenCL 1.1 LINUX&#039;)
---------------------------------------------------------------
(&#039;Device name:&#039;, &#039;      Intel(R) Core(TM) i7-2630QM CPU @ 2.00GHz&#039;)
(&#039;Device type:&#039;, &#039;CPU&#039;)
(&#039;Device memory: &#039;, 5864, &#039;MB&#039;)
(&#039;Device max clock speed:&#039;, 2000, &#039;MHz&#039;)
(&#039;Device compute units:&#039;, 8)
Execution time of test: 0.000382 s
Results OK
===============================================================
(&#039;Platform name:&#039;, &#039;NVIDIA CUDA&#039;)
(&#039;Platform profile:&#039;, &#039;FULL_PROFILE&#039;)
(&#039;Platform vendor:&#039;, &#039;NVIDIA Corporation&#039;)
(&#039;Platform version:&#039;, &#039;OpenCL 1.1 CUDA 4.2.1&#039;)
---------------------------------------------------------------
(&#039;Device name:&#039;, &#039;GeForce GT 540M&#039;)
(&#039;Device type:&#039;, &#039;GPU&#039;)
(&#039;Device memory: &#039;, 2047, &#039;MB&#039;)
(&#039;Device max clock speed:&#039;, 1344, &#039;MHz&#039;)
(&#039;Device compute units:&#039;, 2)
Execution time of test: 0.000624512 s
Results OK</description>
		<content:encoded><![CDATA[<p>pm,</p>
<p>You need to run the test 1000 times. Like:<br />
time1 = time()<br />
for i in range(1000):<br />
        c_result = (a + b) * (a + b) * (a / 2.0)<br />
time2 = time()<br />
print(&#8220;Execution time with numpy: &#8220;, time2 &#8211; time1, &#8220;s&#8221;)</p>
<p>You will see OpenCL performs better than NumPy (but NumPy is still pretty good, IMHO). On my machine:</p>
<p>(&#8216;Execution time of test without OpenCL: &#8216;, 9.549367904663086, &#8216;s&#8217;)<br />
(&#8216;Execution time with numpy: &#8216;, 0.01725006103515625, &#8216;s&#8217;)<br />
===============================================================<br />
(&#8216;Platform name:&#8217;, &#8216;Intel(R) OpenCL&#8217;)<br />
(&#8216;Platform profile:&#8217;, &#8216;FULL_PROFILE&#8217;)<br />
(&#8216;Platform vendor:&#8217;, &#8216;Intel(R) Corporation&#8217;)<br />
(&#8216;Platform version:&#8217;, &#8216;OpenCL 1.1 LINUX&#8217;)<br />
&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;<br />
(&#8216;Device name:&#8217;, &#8216;      Intel(R) Core(TM) i7-2630QM CPU @ 2.00GHz&#8217;)<br />
(&#8216;Device type:&#8217;, &#8216;CPU&#8217;)<br />
(&#8216;Device memory: &#8216;, 5864, &#8216;MB&#8217;)<br />
(&#8216;Device max clock speed:&#8217;, 2000, &#8216;MHz&#8217;)<br />
(&#8216;Device compute units:&#8217;, 8)<br />
Execution time of test: 0.000382 s<br />
Results OK<br />
===============================================================<br />
(&#8216;Platform name:&#8217;, &#8216;NVIDIA CUDA&#8217;)<br />
(&#8216;Platform profile:&#8217;, &#8216;FULL_PROFILE&#8217;)<br />
(&#8216;Platform vendor:&#8217;, &#8216;NVIDIA Corporation&#8217;)<br />
(&#8216;Platform version:&#8217;, &#8216;OpenCL 1.1 CUDA 4.2.1&#8242;)<br />
&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;<br />
(&#8216;Device name:&#8217;, &#8216;GeForce GT 540M&#8217;)<br />
(&#8216;Device type:&#8217;, &#8216;GPU&#8217;)<br />
(&#8216;Device memory: &#8216;, 2047, &#8216;MB&#8217;)<br />
(&#8216;Device max clock speed:&#8217;, 1344, &#8216;MHz&#8217;)<br />
(&#8216;Device compute units:&#8217;, 2)<br />
Execution time of test: 0.000624512 s<br />
Results OK</p>
]]></content:encoded>
	</item>
	<item>
		<title>Comment on Adventures in PyOpenCL: Part 2, Particles with PyOpenGL by Ryan</title>
		<link>http://enja.org/2011/03/22/adventures-in-pyopencl-part-2-particles-with-pyopengl/comment-page-1/#comment-1913</link>
		<dc:creator>Ryan</dc:creator>
		<pubDate>Sun, 29 Apr 2012 16:50:01 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=493#comment-1913</guid>
		<description>Thanks for this.  I hacked the nbody algo into the kernel.  It works fantastic on my gtx285 with around 10k particles.</description>
		<content:encoded><![CDATA[<p>Thanks for this.  I hacked the nbody algo into the kernel.  It works fantastic on my gtx285 with around 10k particles.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Comment on Adventures in OpenCL Part 3: Constant Memory Structs by Emanuel Ey</title>
		<link>http://enja.org/2011/03/30/adventures-in-opencl-part-3-constant-memory-structs/comment-page-1/#comment-1893</link>
		<dc:creator>Emanuel Ey</dc:creator>
		<pubDate>Tue, 17 Apr 2012 10:26:16 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=521#comment-1893</guid>
		<description>So i have been playing around with passing structures to OpenCL kernels as well, and I&#039;ve actually been able to pass structs directly (i.e., without a pointer).
I did this in C, but it should be easy to adapt for C++.

Here are the most relevant points from the host code:
&lt;code&gt;
typedef struct{
    cl_uchar    cDist;
    cl_uchar    cClass
    float       y[N_POINTS_DEPTH];
    float       x[N_POINTS_RANGE];
    float       c1D[N_POINTS_DEPTH];
}myStruct_t;
&lt;/code&gt;

The test kernel takes only 2 arguments, the struct as for input, and another struct of the same type to hold some test data computed from the input. Here&#039;s the host-side memory allocation:
&lt;code&gt;
//instantiate a struct for input:
myStruct_t a;
a.y[0] = 1.4;
a.y[1] = 2.5;

//allocate memory for output:
cl_mem out = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(myStruct_t), NULL, &amp;errNum);
    if(errNum != CL_SUCCESS){
        fatal(clError(errNum));
    }else{
        DEBUG(2, &quot;Successfully allocated memory for output.\n&quot;);
    }
&lt;/code&gt;

Then, set the kernel args:
&lt;code&gt;
    errNum = clSetKernelArg(kernel, 0, sizeof(myStruct_t), &amp;a);
    errNum &#124;= clSetKernelArg(kernel, 1, sizeof(cl_mem), &amp;out);
    if (errNum != CL_SUCCESS){
        fprintf(stderr, &quot;Error setting kernel arguments.\n&quot;);
        fatal(clError(errNum));
        exit(EXIT_FAILURE);
    }else{
        DEBUG(2, &quot;Successfully defined kernel arguments.\n&quot;);
    }
&lt;/code&gt;

The kernel:
&lt;code&gt;
__kernel void testStructs( private myStruct_t soundIn,
                                               global myStruct_t *result){
    local myStruct_t      ssp;
   
    ssp.y[0] = 2*soundIn.y[0];
    ssp.y[1] = 2*soundIn.y[1];
    
    *result = ssp;
}
&lt;/code&gt;

So from my tests i figured out that apparently you cannot actually use the &#039;constant&#039; qualifier when passing in a struct, it has to be &#039;private&#039;. This is ok for me, since &#039;constant&#039; is a special type of &#039;global&#039; and reading it comes at a performance penalty anyway. To me it makes sense to have a settings struct in the fastest available memory.
I tested this on an Nvidia GPU with OpenCL 1.1 and on a Intel Ivy Bridge CPU also with a OpenCL 1.1 implementation.</description>
		<content:encoded><![CDATA[<p>So i have been playing around with passing structures to OpenCL kernels as well, and I&#8217;ve actually been able to pass structs directly (i.e., without a pointer).<br />
I did this in C, but it should be easy to adapt for C++.</p>
<p>Here are the most relevant points from the host code:<br />
<code><br />
typedef struct{<br />
    cl_uchar    cDist;<br />
    cl_uchar    cClass<br />
    float       y[N_POINTS_DEPTH];<br />
    float       x[N_POINTS_RANGE];<br />
    float       c1D[N_POINTS_DEPTH];<br />
}myStruct_t;<br />
</code></p>
<p>The test kernel takes only 2 arguments, the struct as for input, and another struct of the same type to hold some test data computed from the input. Here&#8217;s the host-side memory allocation:<br />
<code><br />
//instantiate a struct for input:<br />
myStruct_t a;<br />
a.y[0] = 1.4;<br />
a.y[1] = 2.5;</p>
<p>//allocate memory for output:<br />
cl_mem out = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(myStruct_t), NULL, &amp;errNum);<br />
    if(errNum != CL_SUCCESS){<br />
        fatal(clError(errNum));<br />
    }else{<br />
        DEBUG(2, "Successfully allocated memory for output.\n");<br />
    }<br />
</code></p>
<p>Then, set the kernel args:<br />
<code><br />
    errNum = clSetKernelArg(kernel, 0, sizeof(myStruct_t), &amp;a);<br />
    errNum |= clSetKernelArg(kernel, 1, sizeof(cl_mem), &amp;out);<br />
    if (errNum != CL_SUCCESS){<br />
        fprintf(stderr, "Error setting kernel arguments.\n");<br />
        fatal(clError(errNum));<br />
        exit(EXIT_FAILURE);<br />
    }else{<br />
        DEBUG(2, "Successfully defined kernel arguments.\n");<br />
    }<br />
</code></p>
<p>The kernel:<br />
<code><br />
__kernel void testStructs( private myStruct_t soundIn,<br />
                                               global myStruct_t *result){<br />
    local myStruct_t      ssp;</p>
<p>    ssp.y[0] = 2*soundIn.y[0];<br />
    ssp.y[1] = 2*soundIn.y[1];</p>
<p>    *result = ssp;<br />
}<br />
</code></p>
<p>So from my tests i figured out that apparently you cannot actually use the &#8216;constant&#8217; qualifier when passing in a struct, it has to be &#8216;private&#8217;. This is ok for me, since &#8216;constant&#8217; is a special type of &#8216;global&#8217; and reading it comes at a performance penalty anyway. To me it makes sense to have a settings struct in the fastest available memory.<br />
I tested this on an Nvidia GPU with OpenCL 1.1 and on a Intel Ivy Bridge CPU also with a OpenCL 1.1 implementation.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Comment on A Python Function Timing Decorator by Rndm &#187; Blog Archive &#187; Python generators</title>
		<link>http://enja.org/2011/03/09/a-python-function-timing-decorator/comment-page-1/#comment-1861</link>
		<dc:creator>Rndm &#187; Blog Archive &#187; Python generators</dc:creator>
		<pubDate>Thu, 29 Mar 2012 22:43:20 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=473#comment-1861</guid>
		<description>[...] Interesting article on how to create a timer wrapper in python: timer decorator [...]</description>
		<content:encoded><![CDATA[<p>[...] Interesting article on how to create a timer wrapper in python: timer decorator [...]</p>
]]></content:encoded>
	</item>
	<item>
		<title>Comment on Adventures in PyOpenCL: Part 2, Particles with PyOpenGL by joost</title>
		<link>http://enja.org/2011/03/22/adventures-in-pyopencl-part-2-particles-with-pyopengl/comment-page-1/#comment-1846</link>
		<dc:creator>joost</dc:creator>
		<pubDate>Sun, 25 Mar 2012 20:54:42 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=493#comment-1846</guid>
		<description>I also had the ImportError: cannot import name get_gl_sharing_context_properties first, so I built pyopencl-2011.2 from source.
Then I had the  &#039;GL_CONTEXT_KHR&#039; exception, which I tried to solve by following the advice above, but after some trial-and-error this worked for me: 
./configure.py --cl-enable-gl

i am on Kubuntu 11.10 (same as Ubuntu), using the most recent nvidia driver.</description>
		<content:encoded><![CDATA[<p>I also had the ImportError: cannot import name get_gl_sharing_context_properties first, so I built pyopencl-2011.2 from source.<br />
Then I had the  &#8216;GL_CONTEXT_KHR&#8217; exception, which I tried to solve by following the advice above, but after some trial-and-error this worked for me:<br />
./configure.py &#8211;cl-enable-gl</p>
<p>i am on Kubuntu 11.10 (same as Ubuntu), using the most recent nvidia driver.</p>
]]></content:encoded>
	</item>
	<item>
		<title>Comment on [RTPS] Fluid and Rigid body interaction by Conzul</title>
		<link>http://enja.org/2011/12/01/rtps-fluid-and-rigid-body-interaction/comment-page-1/#comment-1764</link>
		<dc:creator>Conzul</dc:creator>
		<pubDate>Tue, 06 Mar 2012 16:07:44 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=722#comment-1764</guid>
		<description>This looks amazing! True Particle physics has been the only major thing lacking in the BGE. I&#039;ve been psyching myself to learn CryEngine or UDK, but this makes me want to revisit BGE as an option. After all, why limit your product to one OS when with blender you can get it out to three or more?</description>
		<content:encoded><![CDATA[<p>This looks amazing! True Particle physics has been the only major thing lacking in the BGE. I&#8217;ve been psyching myself to learn CryEngine or UDK, but this makes me want to revisit BGE as an option. After all, why limit your product to one OS when with blender you can get it out to three or more?</p>
]]></content:encoded>
	</item>
	<item>
		<title>Comment on [dd3] d3.js selection tutorial by Gavin Kistner</title>
		<link>http://enja.org/2011/12/05/dd3-d3-js-selection-tutorial/comment-page-1/#comment-1756</link>
		<dc:creator>Gavin Kistner</dc:creator>
		<pubDate>Thu, 01 Mar 2012 20:13:58 +0000</pubDate>
		<guid isPermaLink="false">http://enja.org/?p=727#comment-1756</guid>
		<description>Very nice. I&#039;ve just developed an interactive D3.js playground tool (http://phrogz.net/JS/d3-playground/) and was pointed to yours and found the screencast.</description>
		<content:encoded><![CDATA[<p>Very nice. I&#8217;ve just developed an interactive D3.js playground tool (<a href="http://phrogz.net/JS/d3-playground/" rel="nofollow">http://phrogz.net/JS/d3-playground/</a>) and was pointed to yours and found the screencast.</p>
]]></content:encoded>
	</item>
</channel>
</rss>

<!-- Performance optimized by W3 Total Cache. Learn more: http://www.w3-edge.com/wordpress-plugins/

Minified using disk: basic
Page Caching using disk: basic
Database Caching using disk: basic
Object Caching 351/385 objects using disk: basic
Content Delivery Network via Amazon Web Services: CloudFront: d3a9pqeyre6pa0.cloudfront.net

Served from: enja.org @ 2012-05-13 17:35:48 -->